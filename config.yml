# which directory to save the trial outputs
base_output_dir: "outputs"
data_settings: "cfg_data.yml"

data:
  dataset_url: "https://raw.githubusercontent.com/Har-Lab/HumanActivityData/refs/heads/main/data/labeled_activity_data/"
  dataset_name: "har-labs-activity-data"
  raw_dir: "har_data"
  processed_dir: "processed_data"
  # "min_sample","subject", "None"
  balance_setting: "subject"
  window_center_percentage: 0.87
  train_on_sensors: &sns
    - ankle
    - wrist
    - waist
  test_on_sensors:
    # - ankle
    - wrist
    # - waist
  classes: &activity_list
    - jog_treadmill
    - walk_treadmill
    - upstairs
    - downstairs
    # - walk_mixed
    # - walk_sidewalk
  test_size: 0.25
  val_size: 0.25
  window_size: 250
  stride: 5
  ft_col:
    - "x"
    - "y"
    - "z"
    # - "vm"
    # - "time"

partition:
  cross_set_configs: &cfg
    activities_required: *activity_list
    sensors_required: *sns
    min_samples_per_activity: 1000
    # age_range: [20, 30]
    # injury_free: true

  complete_data:
    <<: *cfg

  no_ankle_sensor:
    <<: *cfg
    sensors_required: ['wrist', 'waist']
    sensors_excluded: ['ankle']

  no_jogging_activity:
    <<: *cfg
    has_jogging: false

# which models to test in this trial 
# commenting out models will not test that model
models_tested:
  - random_forest
  - transformer

# which metrics to use in testing our models, 
# commenting out metrics will not test that metric
evaluation_metrics:
  - accuracy
  - confusion_matrix
  - classification_report
  - ROC_AUC
  - val_batch_examples

wandb:
  # mode: online, offline, disabled
  mode: "disabled"
  entity: "alex-alvarez1903-loyola-marymount-university"
  project: "Har-Transformer-New"
  model_versioning: false


random_forest:
  extracted_features:
    # - "mean"
    - "std"
    # - "max"
    # - "min"
    # - "q75"
    # - "q25"
    # - "iqr"
    - "mad"
    # - "skewness"
  n_estimators: 100
  max_depth: 10
  min_samples_split: 2
  min_samples_leaf: 1

transformer:
  extracted_features:
    # - "mean"
    - "std"
    # - "max"
    # - "min"
    # - "q75"
    # - "q25"
    # - "iqr"
    - "mad"
    # - "skewness"
  
  warmup_ratio: 0.1
  min_lr_ratio: 0.0
  batch_size: 64
  patience: 15
  learning_rate: 0.0015
  weight_decay: 0.0
  epochs: 1
  d_model: 66
  fc_hidden_dim: 128
  nhead: 6
  num_layers: 2
  dropout: 0.1
  load_model_path: ''
  patch_size: 16
  kernel_stride: 4


#   ```

#                                                                                                                                                                                                                                                                                                                                                                                 (har-transformer|Alex Alvarez --> stats_pipeline)  (har)
# Loading data from processed_data/data-ee06a1a0aefd9fa43ff0bd5e1785ec84d0b4b3da9df7dcc06b5f99dcb92787e4.pkl
# X_train shape: torch.Size([68928, 250, 3])
# X_val shape: torch.Size([38400, 250, 3])
# X_test shape: torch.Size([13644, 250, 3])
# Classes: [0 1 2 3]
# AccelTransformerV1(
#   (stats): TorchStatsPipeline(
#     (stats_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)
#   )
#   (patch_embedding): SensorPatches(
#     (projection): Conv1d(3, 66, kernel_size=(16,), stride=(8,), padding=valid)
#   )
#   (pos_encoder): LearnablePositionalEncoding(
#     (position_embedding): Embedding(31, 66)
#   )
#   (transformer_encoder): TransformerEncoder(
#     (layers): ModuleList(
#       (0-1): 2 x TransformerEncoderLayer(
#         (self_attn): MultiheadAttention(
#           (out_proj): NonDynamicallyQuantizableLinear(in_features=66, out_features=66, bias=True)
#         )
#         (linear1): Linear(in_features=66, out_features=198, bias=True)
#         (dropout): Dropout(p=0.1, inplace=False)
#         (linear2): Linear(in_features=198, out_features=66, bias=True)
#         (norm1): LayerNorm((66,), eps=1e-05, elementwise_affine=True)
#         (norm2): LayerNorm((66,), eps=1e-05, elementwise_affine=True)
#         (dropout1): Dropout(p=0.1, inplace=False)
#         (dropout2): Dropout(p=0.1, inplace=False)
#       )
#     )
#   )
#   (meta_proj): Linear(in_features=6, out_features=18, bias=True)
#   (classifier): Sequential(
#     (0): Linear(in_features=84, out_features=128, bias=True)
#     (1): GELU(approximate='none')
#     (2): Dropout(p=0.1, inplace=False)
#     (3): Linear(in_features=128, out_features=4, bias=True)
#   )
# )